import os
import numpy as np
import pandas as pd
from datasets import Dataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, f1_score, classification_report
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    DataCollatorWithPadding,
    TrainingArguments,
    Trainer,
    set_seed
)
from data_utils import load_config, prepare_dataframe, maybe_add_weak_labels

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = np.argmax(logits, axis=-1)
    return {
        "accuracy": accuracy_score(labels, preds),
        "f1_macro": f1_score(labels, preds, average="macro"),
        "f1_weighted": f1_score(labels, preds, average="weighted"),
    }

def main(config_path: str):
    cfg = load_config(config_path)
    set_seed(cfg["training"].get("seed", 42))

    df, text_col, label_col = prepare_dataframe(cfg)
    df, label_col = maybe_add_weak_labels(df, cfg, label_col)

    if label_col is None:
        raise ValueError("No labels available. Provide a label column, enable weak labels, or run zero-shot first.")

    train_df, val_df = train_test_split(
        df[[text_col, label_col]],
        test_size=cfg["training"].get("eval_split", 0.2),
        random_state=cfg["training"].get("seed", 42),
        stratify=df[label_col]
    )

    train_ds = Dataset.from_pandas(train_df.rename(columns={text_col: "text", label_col: "labels"}))
    val_ds = Dataset.from_pandas(val_df.rename(columns={text_col: "text", label_col: "labels"}))

    model_name = cfg["training"]["model_name"]
    tokenizer = AutoTokenizer.from_pretrained(model_name)

    def tok(batch):
        return tokenizer(batch["text"], truncation=True, max_length=cfg["training"]["max_length"])

    train_ds = train_ds.map(tok, batched=True)
    val_ds = val_ds.map(tok, batched=True)

    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)
    collator = DataCollatorWithPadding(tokenizer=tokenizer)

    out_dir = cfg["training"]["output_dir"]
    os.makedirs(out_dir, exist_ok=True)

    args = TrainingArguments(
        output_dir=out_dir,
        evaluation_strategy="epoch",
        save_strategy="epoch",
        learning_rate=cfg["training"]["learning_rate"],
        per_device_train_batch_size=cfg["training"]["batch_size"],
        per_device_eval_batch_size=cfg["training"]["batch_size"],
        num_train_epochs=cfg["training"]["epochs"],
        weight_decay=0.01,
        logging_dir=os.path.join(out_dir, "logs"),
        load_best_model_at_end=True,
        metric_for_best_model="f1_macro",
        greater_is_better=True,
        seed=cfg["training"].get("seed", 42),
        report_to=[]
    )

    trainer = Trainer(
        model=model,
        args=args,
        train_dataset=train_ds,
        eval_dataset=val_ds,
        tokenizer=tokenizer,
        data_collator=collator,
        compute_metrics=compute_metrics
    )

    trainer.train()

    preds = np.argmax(trainer.predict(val_ds).predictions, axis=-1)
    y_true = val_df[label_col].to_numpy()
    print("Validation Report:\n", classification_report(y_true, preds, digits=4))

    model.save_pretrained(out_dir)
    tokenizer.save_pretrained(out_dir)
    print(f"[OK] Saved fine-tuned model to {out_dir}")

if __name__ == "__main__":
    import argparse
    ap = argparse.ArgumentParser()
    ap.add_argument("--config", type=str, default="config.yaml")
    args = ap.parse_args()
    main(args.config)
    
    
    